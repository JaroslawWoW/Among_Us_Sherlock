{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ba115605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "import json\n",
    "import ast\n",
    "import csv\n",
    "from openpyxl import Workbook\n",
    "import pandas as pd\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "from ultralytics import settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e73822d",
   "metadata": {},
   "source": [
    "## 1. Prepare for YALO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8520e3ad",
   "metadata": {},
   "source": [
    "### 1.1 Split datatest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "83c322e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_image = os.listdir(\"E:\\\\Project Sherlock\\\\Grafiki\\\\Grafiki total\\\\Generated_maps\")\n",
    "files_labels = os.listdir(\"E:\\\\Project Sherlock\\\\Grafiki\\\\Grafiki total\\\\Generated_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "40eb44c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "files = list(range(0,1500))  # żeby nie modyfikować oryginału\n",
    "random.shuffle(files)\n",
    "\n",
    "# Określ proporcje\n",
    "total = len(files)\n",
    "test_split = int(0.2 * total)\n",
    "val_split = int(0.2 * total)  # możesz zmienić np. na 0.1\n",
    "train_split = total - test_split - val_split\n",
    "\n",
    "# Podział bez zwracania\n",
    "test = files[:test_split]\n",
    "val = files[test_split:test_split+val_split]\n",
    "train = files[test_split+val_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6c0e3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3febff3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d187e1af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11b54323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba72a81",
   "metadata": {},
   "source": [
    "### 1.2 Distribute the files to specific folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b441d",
   "metadata": {},
   "source": [
    "#### 1.2.1 Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eeeff51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test:\n",
    "    os.rename(\"E://Project Sherlock//Grafiki//Grafiki total//Generated_maps//Map_{}.jpg\".format(x),\n",
    "             \"E://Project Sherlock//Grafiki//Grafiki total//dataset//images//test//Map_{}.jpg\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a62b8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train:\n",
    "    os.rename(\"E://Project Sherlock//Grafiki//Grafiki total//Generated_maps//{}\".format(\"Map_{}.jpg\".format(str(x))),\n",
    "             \"E://Project Sherlock//Grafiki//Grafiki total//dataset//images//train//{}\".format(\"Map_{}.jpg\".format(str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ee3f975",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in val:\n",
    "    os.rename(\"E://Project Sherlock//Grafiki//Grafiki total//Generated_maps//{}\".format(\"Map_{}.jpg\".format(str(x))),\n",
    "             \"E://Project Sherlock//Grafiki//Grafiki total//dataset//images//val//{}\".format(\"Map_{}.jpg\".format(str(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ff1db0",
   "metadata": {},
   "source": [
    "#### 1.2.2 Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6be91072",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test:\n",
    "    os.rename(\"E://Project Sherlock//Grafiki//Grafiki total//Generated_labels//Map_{}.txt\".format(x),\n",
    "             \"E://Project Sherlock//Grafiki//Grafiki total//dataset//labels//test//Map_{}.txt\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e40b4262",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train:\n",
    "    os.rename(\"E://Project Sherlock//Grafiki//Grafiki total//Generated_labels//{}\".format(\"Map_{}.txt\".format(str(x))),\n",
    "             \"E://Project Sherlock//Grafiki//Grafiki total//dataset//labels//train//{}\".format(\"Map_{}.txt\".format(str(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac9bbd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in val:\n",
    "    os.rename(\"E://Project Sherlock//Grafiki//Grafiki total//Generated_labels//{}\".format(\"Map_{}.txt\".format(str(x))),\n",
    "             \"E://Project Sherlock//Grafiki//Grafiki total//dataset//labels//val//{}\".format(\"Map_{}.txt\".format(str(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84358872",
   "metadata": {},
   "source": [
    "### 2.0 Begin training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae9cb764-5f26-4cea-80e2-33138a5929ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update a setting\n",
    "settings.update({\"runs_dir\": \"E:\\\\Project Sherlock\\\\Grafiki\\\\Grafiki total\\\\dataset\"})\n",
    "settings.update({\"datasets_dir\": \"E:\\\\Project Sherlock\\\\Grafiki\\\\Grafiki total\\\\dataset\"})\n",
    "settings.update({\"weights_dir\": \"E:\\\\Project Sherlock\\\\Grafiki\\\\Grafiki total\\\\dataset\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53b6e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"E:\\\\Project Sherlock\\\\Grafiki\\\\Grafiki total\\\\dataset\\\\yolov8n.pt\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6319e802-0ebc-477a-936e-74262c941023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.170 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.168  Python-3.10.18 torch-2.7.1+cpu CPU (AMD Ryzen 5 5600X 6-Core Processor)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=E:\\Project Sherlock\\Grafiki\\Grafiki total\\dataset\\data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=E:\\Project Sherlock\\Grafiki\\Grafiki total\\dataset\\yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train32, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=E:\\Project Sherlock\\Grafiki\\Grafiki total\\dataset\\detect\\train32, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.0, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=0, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751507  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,043 parameters, 3,011,027 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2415.6387.0 MB/s, size: 497.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\Project Sherlock\\Grafiki\\Grafiki total\\dataset\\labels\\train.cache... 900 images, 458 backgrounds, 0 \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 2606.3332.5 MB/s, size: 520.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "D:\\anaconda\\envs\\yalo_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\Project Sherlock\\Grafiki\\Grafiki total\\dataset\\labels\\val.cache... 300 images, 150 backgrounds, 0 corr\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to E:\\Project Sherlock\\Grafiki\\Grafiki total\\dataset\\detect\\train32\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "D:\\anaconda\\envs\\yalo_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 1280 train, 1280 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mE:\\Project Sherlock\\Grafiki\\Grafiki total\\dataset\\detect\\train32\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/57 [00:05<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    data='E:\\\\Project Sherlock\\\\Grafiki\\\\Grafiki total\\\\dataset\\\\data.yaml',\n",
    "    epochs=1,\n",
    "    imgsz=1280,\n",
    "    device='cpu'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc065a-4d3f-4d20-96c2-5de9aadc9185",
   "metadata": {},
   "source": [
    "First run\n",
    "results_dict: {\n",
    "  'metrics/precision(B)': 0.0013,        # precyzja\n",
    "  'metrics/recall(B)': 0.7727,           # czułość (recall)\n",
    "  'metrics/mAP50(B)': 0.00395,           # mAP@0.5 (średnia precyzja przy IoU=0.5)\n",
    "  'metrics/mAP50-95(B)': 0.00253,        # mAP@[0.5:0.95] (uśredniona dokładność)\n",
    "  'fitness': 0.0027                      # wartość do optymalizacji modelu\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d57d7f-7e60-4ff3-b802-3affd3a0bda3",
   "metadata": {},
   "source": [
    "Second run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70295e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76278ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
